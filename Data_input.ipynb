{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAmceZltij2l/m82/EHCrP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majoduran/Denovo_immunogenicitymodel/blob/main/Data_input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling Immunogenicity of De Novo Proteins\n",
        "Welcome to our project repository! This document outlines the necessary structure to model the immunogenicity of de novo proteins.\n",
        "\n",
        "## Data Input Requirements\n",
        "The data input for this project consists of two types of datasets: Test dataset and the Training dataset from the models evaluated. Although they differ in content, both datasets must adhere to the same structure. Below is the required format for each input file:\n",
        "\n",
        "### CSV File Structure\n",
        "Each CSV file should contain the following columns in the specified order:\n",
        "\n",
        "Sequence: The protein sequence of interest\n",
        "\n",
        "Length: The length of the sequence.\n",
        "\n",
        "Tm: The melting temperature of the sequence.\n",
        "\n",
        "#### Additional columns\n",
        "The Test dataset contains two extra columns that are important to include for following analysis:\n",
        "\n",
        "Category: The immunogenic classification of the sequence.\n",
        "Immunogenic Score: The known immunogenic score for controls.\n",
        "\n",
        "#### Additional Notes\n",
        "The CSV file must contain a header row with the column names as specified above.\n",
        "\n",
        "Ensure each column is correctly populated as missing or malformed data may lead to processing errors.\n",
        "\n",
        "Once data matches the structure outlined above, place the CSV file in the designated directory within the repository."
      ],
      "metadata": {
        "id": "zjFl_EPdWWLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example Data\n",
        "An example of how the data should be structured is shown below:\n",
        "\n",
        "```\n",
        "PTSSST,133,52.9069,clinically approved,0\n",
        "GPEEEG,15,59.10659,de-immunized mutant, non-self,0\n",
        "MCDLPQ,166,54.9079,clinically approved,0\n",
        "```\n"
      ],
      "metadata": {
        "id": "9ifpxwAaZmwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning Process\n",
        "To ensure the integrity and consistency of the input data, our project includes a robust data cleaning pipeline. This pipeline is designed to read various file types, deduplicate sequences, and save the cleaned output in a standard CSV format.\n",
        "\n",
        "### Overview of the Cleaning Pipeline\n",
        "The pipeline reads data from three supported file formats:\n",
        "\n",
        "Text files (txt): Assumes a space-separated format with specific columns.\n",
        "\n",
        "Excel files (xlsx): Reads data from an Excel spreadsheet.\n",
        "\n",
        "FASTA files (fasta): Parses protein or DNA sequence data.\n",
        "\n",
        "#### Deduplication Function\n",
        "The core function, deduplicate_and_save, follows these steps:\n",
        "\n",
        "Input Reading: Depending on the specified file type, the function reads the corresponding input file.\n",
        "\n",
        "Deduplication: The function removes duplicate sequences by keeping only the first occurrence, based on the sequence identity.\n",
        "\n",
        "#### Data Processing:\n",
        "For text files, it reads the data into a DataFrame, specifying columns for Sequence, Length, Tm, Category, and Immunogenic Score.\n",
        "\n",
        "For Excel files, it loads the entire sheet into a DataFrame.\n",
        "\n",
        "For FASTA files, it extracts sequences and creates a DataFrame from them.\n",
        "\n",
        "### Usage Instructions\n",
        "Place your input files in an accessible directory.\n",
        "Modify the input_file path and file_type argument in the deduplicate_and_save function calls in the main block as needed.\n",
        "Run the script to perform the cleaning and generate a deduplicated output CSV file."
      ],
      "metadata": {
        "id": "jocdhN-ja0mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning Code\n",
        "\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup logging configuration\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def deduplicate_and_save(input_file, output_file, file_type):\n",
        "    \"\"\"\n",
        "    Reads various file types, deduplicates the sequences, and saves to a specified output file.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): The path to the input file (text, Excel, or FASTA).\n",
        "        output_file (str): The path for the output deduplicated file (CSV).\n",
        "        file_type (str): The type of the input file ('txt', 'excel', or 'fasta').\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read the input file based on its type\n",
        "        if file_type == 'txt':\n",
        "            # Read the file, allowing for both possible structures\n",
        "            df = pd.read_csv(input_file, sep=r'\\s+', header=None, names=['Sequence', 'Length', 'Tm', 'Category', 'Immunogenic_Score'])\n",
        "\n",
        "            # Check if additional columns are present\n",
        "            if df['Category'].isnull().all() and df['Immunogenic_Score'].isnull().all():\n",
        "                df = df[['Sequence', 'Length', 'Tm']]  # Keep only the necessary columns\n",
        "\n",
        "        elif file_type == 'excel':\n",
        "            df = pd.read_excel(input_file)\n",
        "\n",
        "        elif file_type == 'fasta':\n",
        "            with open(input_file, \"r\") as file:\n",
        "                fasta_data = file.read()\n",
        "\n",
        "            entries = fasta_data.split(\">\")[1:]  # Skip the first empty split\n",
        "            data = [{\"Sequence\": \"\".join(entry.split(\"\\n\")[1:]).strip()} for entry in entries]\n",
        "            df = pd.DataFrame(data)\n",
        "\n",
        "        else:\n",
        "            logging.error(\"Unsupported file type provided.\")\n",
        "            return\n",
        "\n",
        "        # Deduplicate entries based on the 'Sequence' column\n",
        "        clean_df = df.drop_duplicates(subset=[\"Sequence\"], keep=\"first\")\n",
        "        clean_df.to_csv(output_file, index=False)\n",
        "        logging.info(f\"Deduplicated data saved to {output_file}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        logging.error(f\"File not found: {input_file}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred in processing the {file_type} file: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example configuration options\n",
        "    input_files = [\n",
        "        {'path': 'input_data/sample_data.txt', 'type': 'txt'},\n",
        "        {'path': 'input_data/sample_data.xlsx', 'type': 'excel'},\n",
        "        {'path': 'input_data/sample_data.fasta', 'type': 'fasta'}\n",
        "    ]\n",
        "    output_csv = 'deduplicated_sequences.csv'\n",
        "\n",
        "    # Process each input file\n",
        "    for input_info in input_files:\n",
        "        deduplicate_and_save(input_info['path'], output_csv, input_info['type'])"
      ],
      "metadata": {
        "id": "D5KbSaCcZeT1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}